In this assignment I am going to fit a multiple regression model on the dataset human and I will try to make predictions from it.
Furthermore I will conduct linear discriminant analysis (LDA) with the data, train the LDA-model and try the model on a testing data set.

#1. The dataset "human"
The dataset originates from the [United Nationa Development Programme (UNDP)](http://hdr.undp.org/en/content/human-development-index-hdi). The UNDP aims to compare the development of countries and regions of the world, including not only growth alone, but many different variables. In this exercise we are using a subset, that I created from the original data. I selected certain variables concerning health and education as well as the Human Development Index (HDI) and the Gross National Income per capita (GNI). Missing values were removed from the dataset. The file of the data wrangling can be found here. The dataset contains 155 observations of 8 variables. The observations are made for 155 countries. The variables are:

* **HDI:** Human Development index
* **Edu2.FM:** Ratio of women with at least secondary education to men with at least seconday reducation
* **Life.Exp:** Life expectancy at birth
* **Mean.Edu:** mean years of education
* **GNI:** Gross National Income per capita
* **Mat.Mor:** Maternal mortality ratio
* **Ado.Birth:** Adolescent birth rate
* **Parli.F:** Percentage of female representatives in parliament

```{r data human}
#At first I am accessing all the packages that I will be using during this exercise
library(GGally)
library(ggplot2)
library(MASS)
#Now we read the data
human <- read.csv("/Users/eva-mariaroth/Documents/GitHub/IODS-final/human_.csv", header = TRUE, sep= ",")
#Exploring the data, its structur and dimensions
str(human)
```
I want to take a closer look at the variables and their relationships to each other. For this I can pair the variables see if there are correlations.The correlation matrix shows us the distribution of the data for each variable. The variables are paired and the results are shown graphically in scatter plots and with the Correlation Coefficient. The highest correlation we can find between Life Expectancy and HDI with a correlation coefficient of 0.905.
```{r human pairs}
p <- ggpairs(human, mapping = aes(), lower = list(combo = wrap("facethist", bins = 20)))
p
```

# 2. Simple regression
```{r simple regr scatterplot}
#creating a scatter plot of Life.Exp versus Mean.Edu with a linear regression line
qplot(Life.Exp, Mean.Edu, data = human) + geom_smooth(method = "lm")
```


```{r simple regr}
#fitting a linear model where Life.Exp is the target, whereas mean. edu is the explanatory variable
my_model <- lm(Life.Exp ~ Mean.Edu, data = human)
summary(my_model)
```

###2.1 Making predictions using the model
```{r predict}
#predicting
m <- lm(Life.Exp ~ Mean.Edu, data = human)

# print out a summary of the model
summary(m)

# New observations
new_mean.edu <- c("Niger" = 12.1, "Chad"= 11.5, "Mali" = 10.3, "Nepal" = 10.5, "Haiti" =11,7, "Yemen" = 10)
new_data <- data.frame(Mean.Edu = new_mean.edu)

# Print out the new data
new_data
predict(m, newdata = new_data)
```




# 3 Multiple regression model


```{r multipl regr}
#fitting a multiple regression model with several explanatory variables
my_model2 <- lm(Life.Exp ~ Mean.Edu + Edu2.FM + Parli.F, data =human)
summary(my_model2)
```

```{r validity}
#exploring validity of the model by drawing diagnostic plots
par(mfrow = c(2,2))
plot(my_model2, which = c(1,2,5))
```

```{r diagnostic2}
par(mfrow = c(2,2))
plot(my_model, which = c(1,2,5))
```
# 4 Performing Linear Discriminant analysis
```{r scaling}
#keep only the columns regarding health and education
human2 <- read.csv("/Users/eva-mariaroth/Documents/GitHub/IODS-final/human2.csv", header = TRUE, sep= ",")
human_scaled <- scale(human2)
# summaries of the scaled variables
summary(human_scaled)
```
```{r class}
# class of the boston_scaled object
class(human_scaled)

# change the object to data frame
human_scaled <- as.data.frame(human_scaled)
summary(human_scaled$Life.Exp)
bins <- quantile(human_scaled$Life.Exp)
bins
#create a categorical variable crime
Lifeexp <- cut(human_scaled$Life.Exp, breaks = bins, include.lowest = TRUE, labels = c("low", "med_low", "med_high", "high"))
table(Lifeexp)
```
```{r train test.}
#remove original Life.Exp variable from the dataset
human_scaled <- dplyr::select(human_scaled, -Life.Exp)
#add the new categorical value to scaled data
human_scaled <- data.frame(human_scaled, Lifeexp)
str(human_scaled)
```
```{r train test}
n<- nrow(human_scaled)
#choose randomly 80% of the rows
ind <-sample(n, size = n*0.8)
#create train set
train <- human_scaled[ind,]
#create test set
test <- human_scaled[-ind,]
# save the correct classes from the test data
correct_classes <- test$Lifeexp
#remove the Lifeexp variable from the test data
test <- dplyr::select(test, -Lifeexp)
```

###linear discriminant analysis

```{r lda}
lda.fit <- lda(Lifeexp ~ ., data  =train)
#printing the lda.fit object
lda.fit
```
```{r lda arrows}
#lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "deeppink2", tex = 1.25, choices = c(1,2)){
  heads <- coef(x)
  arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)
}
# target classes as numeric
classes <- as.numeric(train$Lifeexp)

# plot the lda results
plot(lda.fit, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 2.5)
```

#Predicting
```{r predict with lda}
# predict classes with test data
lda.pred <- predict(lda.fit, newdata = test)

# cross tabulate the results
table(correct = correct_classes, predicted = lda.pred$class)
```





























plot(mca, invisible=c("ind"), habillage = "quali")
agef <- cut(tea$age, breaks = 4, labels = c("15-30","31-45", "46-50", "50-75", "75-90"))
agef <- cut(tea$age, breaks = 5, labels = c("15-30","31-45", "46-50", "50-75", "75-90"))
tea <- data.frame(tea, agef)
keep_columns <- c("Tea", "agef", "sex", "spirituality", "sophisticated", "exciting", "relaxing", "how", "How", "Tea")
tea_time <- select(tea, one_of(keep_columns))
summary(tea_time)
mca <- MCA(tea_time, graph = FALSE)
summary(mca)
plot(mca, invisible=c("ind"), habillage = "quali")
biplot(pca_human, choices = 1:2, cex = c(0.5, 1), col =c("grey40", "green4"), main = "Principal component analysis on dataset "human" (not scaled)")
biplot(pca_human, choices = 1:2, cex = c(0.5, 1), col =c("grey40", "green4"), main = "Principal component analysis on dataset (not scaled)")
biplot(pca_human, choices = 1:2, cex = c(0.5, 1), col =c("grey40", "green4"), main = "Principal component analysis on dataset human (not scaled)")
biplot(pca_human, choices = 1:2, cex = c(0.5, 1), col =c("grey40", "green4"), main = "Principal component analysis on dataset human (not scaled)")
pca_human <- prcomp(human)
biplot(pca_human, choices = 1:2, cex = c(0.5, 1), col =c("grey40", "green4"), main = "Principal component analysis on dataset human (not scaled)")
human <- read.csv("/Users/eva-mariaroth/Documents/GitHub/IODS-project/human_.csv", header = TRUE, sep= ",")
str(human)
summary(human)
library(ggplot2)
library(tidyr)
library(GGally)
ggpairs(human)
library(corrplot)
cor_matrix <- cor(human)%>%round(digits=2)
corrplot(cor_matrix, type="upper")
ggpairs(human, title 0 "Table 1. Correlation matrix for paired variables of dataset human")
ggpairs(human, title = "Table 1. Correlation matrix for paired variables of dataset human")
corrplot(cor_matrix, type="upper", title = "Correlation plot for paired variables of dataset human")
biplot(pca_human, choices = 1:2, cex = c(0.5, 1), col =c("grey40", "green4"), main = "PCA on unscaled dataset human - few conclusions can be drawn")
biplot(pca_human, choices = 1:2, cex = c(0.5, 1), col =c("grey40", "green4"), xlab = pc_lab[1], ylab = pc_lab[2], main = "PCA on scaled dataset - correlations visible")
human_std <-scale(human)
pca_human2 <- prcomp(human_std)
s <- summary(pca_human2)
pca_pr <- round(100*s$importance[2, ], digits = 1)
pc_lab <-paste0(names(pca_pr), " (", pca_pr, "%)")
biplot(pca_human, choices = 1:2, cex = c(0.5, 1), col =c("grey40", "green4"), xlab = pc_lab[1], ylab = pc_lab[2], main = "PCA on scaled dataset - correlations visible")
human_std2 <-scale(human)
human_std <-scale(human)
pca_human2 <- prcomp(human_std)
s <- summary(pca_human2)
pca_pr <- round(100*s$importance[2, ], digits = 1)
pc_lab <-paste0(names(pca_pr), " (", pca_pr, "%)")
biplot(pca_human2, choices = 1:2, cex = c(0.5, 1), col =c("grey40", "green4"), xlab = pc_lab[1], ylab = pc_lab[2], main = "PCA on scaled dataset - correlations visible")
dim(human)
head(human)
library(ggplot2)
library(tidyr)
library(GGally)
ggpairs(human, title = "Table 1. Correlation matrix for paired variables of dataset human")
library(corrplot)
#writing the correlation matrix
cor_matrix <- cor(human)%>%round(digits=2)
#drawing the correlation plot
corrplot(cor_matrix, type="upper", title = "Correlation plot for paired variables of dataset human")
library("FactoMineR")
data("tea")
str(tea)
dim(tea)
str(tea)
library(dplyr)
agef <- cut(tea$age, breaks = 5, labels = c("15-30","31-45", "46-50", "50-75", "75-90"))
tea <- data.frame(tea, agef)
keep_columns <- c("Tea", "agef", "sex", "spirituality", "sophisticated", "exciting", "relaxing", "how", "How", "Tea")
tea_time <- select(tea, one_of(keep_columns))
summary(tea_time)
mca <- MCA(tea_time, graph = FALSE)
summary(mca)
plot(mca, invisible=c("ind"), habillage = "quali")
keep_columns <- c("Tea", "agef", "sex", "spirituality", "sophisticated", "relaxing", "how", "How", "Tea")
tea_time <- select(tea, one_of(keep_columns))
summary(tea_time)
mca <- MCA(tea_time, graph = FALSE)
summary(mca)
plot(mca, invisible=c("ind"), habillage = "quali")
library(MASS)
#calculate optimal number of clusters
set.seed(123)
library(GGally)
library(ggplot2)
human <- read.csv("/Users/eva-mariaroth/Documents/GitHub/IODS-final/human_.csv", header = TRUE, sep= ",")
#determine the number of clusters
k_max <-10
# calculating the total within sum of squares
twcss <- sapply(1:k_max, function(k){kmeans(human, k)$tot.withinss})
#visualize the results
qplot(x = 1:k_max, y = twcss, geom = 'line')
#At first I am accessing all the packages that I will be using during this exercise
library(GGally)
library(ggplot2)
library(MASS)
#Now we read the data
human <- read.csv("/Users/eva-mariaroth/Documents/GitHub/IODS-final/human_.csv", header = TRUE, sep= ",")
#Exploring the data, its structur and dimensions
str(human)
p <- ggpairs(human, mapping = aes(), lower = list(combo = wrap("facethist", bins = 20)))
p
#At first I am accessing all the packages that I will be using during this exercise
library(GGally)
library(ggplot2)
library(MASS)
#Now we read the data
human <- read.csv("/Users/eva-mariaroth/Documents/GitHub/IODS-final/human_.csv", header = TRUE, sep= ",")
#Exploring the data, its structur and dimensions
str(human)
p <- ggpairs(human, mapping = aes(), lower = list(combo = wrap("facethist", bins = 20)))
p
# loading the cvs tables "Human development" and "Gender inequality" into R.
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", stringsAsFactors = F, na.strings = "..")
# Exploring the structures and dimensions.
dim(hd)
str(hd)
summary(hd)
dim(gii)
str(gii)
summary(gii)
# Renaming the variables
colnames(hd)
colnames(hd)[1]<-"HDI.rank"
colnames(hd)[2]<-"Country"
colnames(hd)[3]<-"HDI"
colnames(hd)[4]<-"Life.Exp"
colnames(hd)[5]<-"Edu.Exp"
colnames(hd)[6]<-"Mean.Edu"
colnames(hd)[7]<-"GNI"
colnames(hd)[8]<-"GNI.rank-HDI.rank"
colnames(gii)[1]<-"GII.rank"
colnames(gii)[2]<-"Country"
colnames(gii)[3]<-"GII"
colnames(gii)[4]<-"Mat.Mor"
colnames(gii)[5]<-"Ado.Birth"
colnames(gii)[6]<-"Parli.F"
colnames(gii)[7]<-"edu2F"
colnames(gii)[8]<-"edu2M"
colnames(gii)[9]<-"labF"
colnames(gii)[10]<-"labM"
#Mutating the "Gender inequality" data in order to create a new variable.
#First accessing the tidyverse package dplyr
library(dplyr)
gii <- mutate(gii, Edu2.FM = gii$edu2F/gii$edu2M)
colnames(gii)
summary(gii$ratio.edu2)
summary(gii$ratio.lab)
#Joining the two datasets using the variable country as the identifier.
human <- inner_join(hd, gii, by = "Country")
dim(human)
#The dataset human has 195 observations of 19 variables
glimpse(human)
#Mutating data. Transforming Gross National Income (GNI) variable to numeric, using string manipulation
dim(human)
str(human$GNI)
library(stringr)
GNI2 <- str_replace(human$GNI, pattern=",", replace ="") %>% as.numeric
human <- mutate(human, GNI2)
str(human$GNI2)
dim(human)
colnames(human)
#Selecting certain variables and excluding the rest.
keep <- c("HDI", "Country", "Edu2.FM", "Life.Exp", "Mean.Edu", "GNI2", "Mat.Mor", "Ado.Birth", "Parli.F")
human <- select(human, one_of(keep))
colnames(human)
#Renaming the column GNI2 (the variable GNI, transformed into numeric) back to GNI
colnames(human)[6]<-"GNI"
colnames(human)
#Removing all the rows with missing values
complete.cases(human)
data.frame(human[-1], comp = complete.cases(human))
human_ <- filter(human, complete.cases(human))
str(human_)
#The last seven observations are not concerning countries, but regions. We want to exclude them from the dataset.
tail(human_, n=10)
last <- nrow(human) -7
human_ <- human_ [1:155,]
str(human_)
#Defining the row names by the country names and removing the country name column from the data.
rownames(human_) <- human_$Country
str(human_)
human_ <- select(human_, -Country)
str(human_)
#Setting the working directory
setwd("/Users/eva-mariaroth/Documents/GitHub/IODS-final")
#Saving the data
write.table(human_, file = "human_.csv", sep = ",", row.names = TRUE, col.names = TRUE)
#At first I am accessing all the packages that I will be using during this exercise
library(GGally)
library(ggplot2)
library(MASS)
#Now we read the data
human <- read.csv("/Users/eva-mariaroth/Documents/GitHub/IODS-final/human_.csv", header = TRUE, sep= ",")
#Exploring the data, its structur and dimensions
str(human)
#fitting a multiple regression model with several explanatory variables
my_model2 <- lm(Life.Exp ~ Mean.Edu + Edu2.FM + Parli.F, data =human)
summary(my_model2)
#exploring validity of the model by drawing diagnostic plots
par(mfrow = c(2,2))
plot(my_model2, which = c(1,2,5))
#predicting
m <- lm(Life.Exp ~ Mean.Edu+Edu2.FM +Parli.F, data = human)
# print out a summary of the model
summary(m)
# New observations
new_Mean.Edu <- c("Niger" = 12.1, "Chad"= 11.5, "Mali" = 10.3, "Nepal" = 10.5, "Haiti" =11,7, "Yemen" = 10)
new_data <- data.frame(Mean.Edu = new_Mean.Edu)
# Print out the new data
new_data
predict(m, newdata = new_data)
new_data <- data.frame(Mean.Edu = new_Mean.Edu, human$Edu2.FM, human$Parli.F)
View(human)
new_data <- data.frame(Mean.Edu = new_Mean.Edu, human$Edu2.FM[155, 153, 148, 123, 135, 132], human$Parli.F[155, 153, 148, 123, 135, 132])
new_data <- data.frame(Mean.Edu = new_Mean.Edu, human$Edu2.FM[1, 155, 153, 148, 123, 135, 132], human$Parli.F[1, 155, 153, 148, 123, 135, 132])
#creating a scatter plot of Life.Exp versus Mean.Edu with a linear regression line
qplot(Life.Exp, Mean.Edu, data = human) + geom_smooth(method = "lm")
#fitting a linear model where Life.Exp is the target, whereas mean. edu is the explanatory variable
my_model <- lm(Life.Exp ~ Mean.Edu, data = human)
summary(my_model)
#predicting
m <- lm(Life.Exp ~ Mean.Edu, data = human)
# print out a summary of the model
summary(m)
# New observations
new_mean.edu <- c("Niger" = 12.1, "Chad"= 11.5, "Mali" = 10.3, "Nepal" = 10.5, "Haiti" =11,7, "Yemen" = 10)
new_data <- data.frame(Mean.Edu = new_mean.edu)
# Print out the new data
new_data
predict(m, newdata = new_data)
#fitting a multiple regression model with several explanatory variables
my_model2 <- lm(Life.Exp ~ Mean.Edu + Edu2.FM + Parli.F, data =human)
summary(my_model2)
#exploring validity of the model by drawing diagnostic plots
par(mfrow = c(2,2))
plot(my_model2, which = c(1,2,5))
plot(my_model2, which = c(2))
plot(my_model2, which = c(1))
plot(my_model2, which = c(5))
p <- ggpairs(human, mapping = aes(), lower = list(combo = wrap("facethist", bins = 20)))
p
errorse <- plot(my_model2, which = c(1)), par(mfrow = c(2,2))
errorse <- plot(my_model2, which = c(1), par(mfrow = c(2,2)))
plot(my_model2, which = c(1,2,5))
plot(my_model, which = c(1,2,5))
par(mfrow = c(2,2))
plot(my_model, which = c(1,2,5))
#K-means
#clustering
#scaling the dataset
human_scaled <- scale(human)
# summaries of the scaled variables
summary(human_scaled)
# class of the boston_scaled object
class(human_scaled)
# change the object to data frame
human_scaled <- as.data.frame(human_scaled)
summary(human_scaled$Life.Exp)
bins <- quantile(human_scaled$Life.Exp)
bins
#create a categorical variable crime
Lifeexp <- cut(human_scaled$Life.Exp, breaks = bins, include.lowest = TRUE, labels = c("low", "med_low", "med_high", "high"))
table(Lifeexp)
#remove original Life.Exp variable from the dataset
human_scaled <- dplyr::select(human_scaled, -Life.Exp)
#add the new categorical value to scaled data
human_scaled <- data.frame(human_scaled, Lifeexp)
glimpse(human_scaled)
#scaling the dataset
human_scaled <- scale(human)
# summaries of the scaled variables
summary(human_scaled)
# class of the boston_scaled object
class(human_scaled)
# change the object to data frame
human_scaled <- as.data.frame(human_scaled)
summary(human_scaled$Life.Exp)
bins <- quantile(human_scaled$Life.Exp)
bins
#create a categorical variable crime
Lifeexp <- cut(human_scaled$Life.Exp, breaks = bins, include.lowest = TRUE, labels = c("low", "med_low", "med_high", "high"))
table(Lifeexp)
#remove original Life.Exp variable from the dataset
human_scaled <- dplyr::select(human_scaled, -Life.Exp)
#add the new categorical value to scaled data
human_scaled <- data.frame(human_scaled, Lifeexp)
glimpse(human_scaled)
n<- nrow(human_scaled)
#choose randomly 80% of the rows
ind <-sample(n, size = n*0.8)
#create train set
train <- human_scaled[ind,]
#create test set
test <- human_scaled[-ind,]
# save the correct classes from the test data
correct_classes <- test$Lifeexp
#remove the Lifeexp variable from the test data
test <- dplyr::select(test, -Lifeexp)
lda.fit <- lda(Lifeexp ~ ., data  =train)
#printing the lda.fit object
lda.fit
#lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "orange", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# target classes as numeric
classes <- as.numeric(train$Lifeexp)
# plot the lda results
plot(lda.fit, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 1)
plot(lda.fit, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 1)
# predict classes with test data
lda.pred <- predict(lda.fit, newdata = test)
# cross tabulate the results
table(correct = correct_classes, predicted = lda.pred$class)
#At first I am accessing all the packages that I will be using during this exercise
library(GGally)
library(ggplot2)
library(MASS)
str(humaan_scaled)
str(human_scaled)
#scaling the dataset
human_scaled2 <- scale(human)
#keep only the columns regarding health and education
keep <- c("Country", "Edu2.FM", "Life.Exp", "Mean.Edu", "Mat.Mor", "Ado.Birth", "Parli.F")
human_scaled <- select(human_scaled2, one_of(keep))
human2 <- select(human, one_of(keep))
#scaling the dataset
keep <- c("Edu2.FM", "Life.Exp", "Mean.Edu", "Mat.Mor", "Ado.Birth", "Parli.F")
human2 <- select(human, one_of(keep))
human_scaled <- scale(human2)
#scaling the dataset
#keep only the columns regarding health and edu
keep <- c("Edu2.FM", "Life.Exp", "Mean.Edu", "Mat.Mor", "Ado.Birth", "Parli.F")
human2 <- select(human, one_of(keep))
human_scaled <- scale(human2)
# summaries of the scaled variables
summary(human_scaled)
# class of the boston_scaled object
class(human_scaled)
# change the object to data frame
human_scaled <- as.data.frame(human_scaled)
summary(human_scaled$Life.Exp)
bins <- quantile(human_scaled$Life.Exp)
bins
#create a categorical variable crime
Lifeexp <- cut(human_scaled$Life.Exp, breaks = bins, include.lowest = TRUE, labels = c("low", "med_low", "med_high", "high"))
table(Lifeexp)
#remove original Life.Exp variable from the dataset
human_scaled <- dplyr::select(human_scaled, -Life.Exp)
#add the new categorical value to scaled data
human_scaled <- data.frame(human_scaled, Lifeexp)
str(human_scaled)
n<- nrow(human_scaled)
#choose randomly 80% of the rows
ind <-sample(n, size = n*0.8)
#create train set
train <- human_scaled[ind,]
#create test set
test <- human_scaled[-ind,]
# save the correct classes from the test data
correct_classes <- test$Lifeexp
#remove the Lifeexp variable from the test data
test <- dplyr::select(test, -Lifeexp)
lda.fit <- lda(Lifeexp ~ ., data  =train)
#printing the lda.fit object
lda.fit
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "orange", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# target classes as numeric
classes <- as.numeric(train$Lifeexp)
plot(lda.fit, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 1)
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 1.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# target classes as numeric
classes <- as.numeric(train$Lifeexp)
# plot the lda results
plot(lda.fit, dimen = 2, col = classes, pch = classes)
plot(lda.fit, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 1)
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "orange", tex = 1, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# target classes as numeric
classes <- as.numeric(train$Lifeexp)
plot(lda.fit, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 1)
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "orange3", tex = 1, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# target classes as numeric
classes <- as.numeric(train$Lifeexp)
plot(lda.fit, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 1)
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "orange2", tex = 1.25, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# target classes as numeric
classes <- as.numeric(train$Lifeexp)
# plot the lda results
plot(lda.fit, dimen = 2, col = classes, pch = classes)
plot(lda.fit, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 1)
# predict classes with test data
lda.pred <- predict(lda.fit, newdata = test)
# cross tabulate the results
table(correct = correct_classes, predicted = lda.pred$class)
#keep only the columns regarding health and education
keep <- c("Edu2.FM", "Life.Exp", "Mean.Edu", "Mat.Mor", "Ado.Birth", "Parli.F")
human2 <- select(human, one_of(keep))
human_scaled <- scale(human2)
# summaries of the scaled variables
summary(human_scaled)
# class of the boston_scaled object
class(human_scaled)
# change the object to data frame
human_scaled <- as.data.frame(human_scaled)
summary(human_scaled$Life.Exp)
bins <- quantile(human_scaled$Life.Exp)
bins
#create a categorical variable crime
Lifeexp <- cut(human_scaled$Life.Exp, breaks = bins, include.lowest = TRUE, labels = c("low", "med_low", "med_high", "high"))
table(Lifeexp)
#remove original Life.Exp variable from the dataset
human_scaled <- dplyr::select(human_scaled, -Life.Exp)
#add the new categorical value to scaled data
human_scaled <- data.frame(human_scaled, Lifeexp)
str(human_scaled)
keep <- c("Edu2.FM", "Life.Exp", "Mean.Edu", "Mat.Mor", "Ado.Birth", "Parli.F")
human2 <- select(human, one_of(keep))
write.table(human2, file = "human2.csv", sep = ",", row.names = TRUE, col.names = TRUE)
#keep only the columns regarding health and education
human2 <- read.csv("/Users/eva-mariaroth/Documents/GitHub/IODS-final/human2.csv", header = TRUE, sep= ",")
human_scaled <- scale(human2)
# summaries of the scaled variables
summary(human_scaled)
# class of the boston_scaled object
class(human_scaled)
# change the object to data frame
human_scaled <- as.data.frame(human_scaled)
summary(human_scaled$Life.Exp)
bins <- quantile(human_scaled$Life.Exp)
bins
#create a categorical variable crime
Lifeexp <- cut(human_scaled$Life.Exp, breaks = bins, include.lowest = TRUE, labels = c("low", "med_low", "med_high", "high"))
table(Lifeexp)
#remove original Life.Exp variable from the dataset
human_scaled <- dplyr::select(human_scaled, -Life.Exp)
#add the new categorical value to scaled data
human_scaled <- data.frame(human_scaled, Lifeexp)
str(human_scaled)
n<- nrow(human_scaled)
#choose randomly 80% of the rows
ind <-sample(n, size = n*0.8)
#create train set
train <- human_scaled[ind,]
#create test set
test <- human_scaled[-ind,]
# save the correct classes from the test data
correct_classes <- test$Lifeexp
#remove the Lifeexp variable from the test data
test <- dplyr::select(test, -Lifeexp)
lda.fit <- lda(Lifeexp ~ ., data  =train)
#printing the lda.fit object
lda.fit
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "orange2", tex = 1.25, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# target classes as numeric
classes <- as.numeric(train$Lifeexp)
plot(lda.fit, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 1)
# predict classes with test data
lda.pred <- predict(lda.fit, newdata = test)
# cross tabulate the results
table(correct = correct_classes, predicted = lda.pred$class)
